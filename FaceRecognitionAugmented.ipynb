{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya02shah/FaceRecognition/blob/main/FaceRecognitionAugmented.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XP92HM7W4c3"
      },
      "source": [
        "##Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOqkvKyYW6T9"
      },
      "outputs": [],
      "source": [
        "#Standard Dependancies\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNhM1XZlXGic"
      },
      "outputs": [],
      "source": [
        "##Tensorflow dependencies-Functional API\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense,Layer,Conv2D,MaxPooling2D,Input,Flatten\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_UEoHeWX4Qq"
      },
      "outputs": [],
      "source": [
        "POS_PATH=os.path.join('data','positive')\n",
        "NEG_PATH=os.path.join('data','negative')\n",
        "ANC_PATH=os.path.join('data','anchor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoERDBaxhNvi"
      },
      "outputs": [],
      "source": [
        "os.makedirs(POS_PATH)\n",
        "os.makedirs(NEG_PATH)\n",
        "os.makedirs(ANC_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8NjIa231PqR"
      },
      "source": [
        "##Collecting Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw8a3pOD1TpC",
        "outputId": "1d154926-f941-43fa-866e-ec532500b4b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-21 03:28:08--  http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
            "Resolving vis-www.cs.umass.edu (vis-www.cs.umass.edu)... 128.119.244.95\n",
            "Connecting to vis-www.cs.umass.edu (vis-www.cs.umass.edu)|128.119.244.95|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180566744 (172M) [application/x-gzip]\n",
            "Saving to: ‘lfw.tgz’\n",
            "\n",
            "lfw.tgz             100%[===================>] 172.20M  55.4MB/s    in 3.3s    \n",
            "\n",
            "2023-04-21 03:28:12 (52.3 MB/s) - ‘lfw.tgz’ saved [180566744/180566744]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"http://vis-www.cs.umass.edu/lfw/lfw.tgz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEQckVjJ1qk7"
      },
      "outputs": [],
      "source": [
        "##Uncompress Tar GZ Labelled Faces in the wild Dataset\n",
        "!tar -xf lfw.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKIV2cJM2F7e"
      },
      "outputs": [],
      "source": [
        "#Moving lfw images to data/negative\n",
        "for directory in os.listdir('lfw'):\n",
        "  for filename in os.listdir(os.path.join('lfw',directory)):\n",
        "    CUR_PATH=os.path.join('lfw',directory,filename)\n",
        "    NEW_PATH=os.path.join(NEG_PATH,filename)\n",
        "    os.replace(CUR_PATH,NEW_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAVVmcRR6tyv"
      },
      "source": [
        "##Collect Positives and Anchors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid"
      ],
      "metadata": {
        "id": "JcvaIzB7on_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HxrQW0zWA8Z"
      },
      "outputs": [],
      "source": [
        "#Establish a connection to the webcam\n",
        "cap=cv2.VideoCapture(3)\n",
        "while cap.isOpened():\n",
        "  ret,frame=cap.read()\n",
        "\n",
        "  frame=frame[120:120+250,200:200+250,:]\n",
        "  #Show image back to screen\n",
        "  cv2.imshow(\"Image Collection\",frame)\n",
        "\n",
        "  #Collecting Anchors\n",
        "  if cv2.waitKey(1) & 0XFF == ord('a'):\n",
        "    imgname=os.path.join(ANC_PATH,'{}.jpg'.format(uuid.uuid1()))\n",
        "    cv2.imwrite(imgname,frame)\n",
        "  #Collecting Positives\n",
        "  if cv2.waitKey(1) & 0XFF == ord('p'):\n",
        "    imgname=os.path.join(POS_PATH,'{}.jpg'.format(uuid.uuid1()))\n",
        "    cv2.imwrite(imgname,frame)\n",
        "\n",
        "  #Breaking gracefull\n",
        "  if cv2.waitKey(1) & 0XFF == ord('q'):\n",
        "    break\n",
        "\n",
        "#Release the webcam\n",
        "cap.release()\n",
        "#Close the image show frame\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh5WIzsRYNoj"
      },
      "outputs": [],
      "source": [
        "cap.read??"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hL30fzbIrDck",
        "outputId": "b4d9fd04-1c43-4bdf-cd71-eec32f88f0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/gdrive/MyDrive/ML/data.zip'"
      ],
      "metadata": {
        "id": "FUfYy8lV-TRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Augmentation"
      ],
      "metadata": {
        "id": "4qfx4Z-vuR57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_aug(img):\n",
        "    data = []\n",
        "    for i in range(9):\n",
        "        img = tf.image.stateless_random_brightness(img, max_delta=0.02, seed=(1,2))\n",
        "        img = tf.image.stateless_random_contrast(img, lower=0.6, upper=1, seed=(1,3))\n",
        "        # img = tf.image.stateless_random_crop(img, size=(20,20,3), seed=(1,2))\n",
        "        img = tf.image.stateless_random_flip_left_right(img, seed=(np.random.randint(100),np.random.randint(100)))\n",
        "        img = tf.image.stateless_random_jpeg_quality(img, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100),np.random.randint(100)))\n",
        "        img = tf.image.stateless_random_saturation(img, lower=0.9,upper=1, seed=(np.random.randint(100),np.random.randint(100)))\n",
        "\n",
        "        data.append(img)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "bYv1DWm0uTfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name in os.listdir(os.path.join(POS_PATH)):\n",
        "    img_path = os.path.join(POS_PATH, file_name)\n",
        "    img = cv2.imread(img_path)\n",
        "    augmented_images = data_aug(img)\n",
        "\n",
        "    for image in augmented_images:\n",
        "        cv2.imwrite(os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
      ],
      "metadata": {
        "id": "CMrZ6l5wuVfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name in os.listdir(os.path.join(ANC_PATH)):\n",
        "    img_path = os.path.join(ANC_PATH, file_name)\n",
        "    img = cv2.imread(img_path)\n",
        "    augmented_images = data_aug(img)\n",
        "\n",
        "    for image in augmented_images:\n",
        "        cv2.imwrite(os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
      ],
      "metadata": {
        "id": "L-Uv26mNct91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(os.path.join('/content','data','anchor'))),len(os.listdir(os.path.join('/content','data','positive'))),len(os.listdir(os.path.join('/content','data','negative')))\n",
        "#/content/data/anchor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMnKL5n4veCx",
        "outputId": "1d0ae0b8-a53c-484e-fc80-5ec1e5f0e28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4140, 3160, 13233)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pre-processing Data"
      ],
      "metadata": {
        "id": "oSFgiwvprIJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anchor=tf.data.Dataset.list_files('/content/data/anchor/'+'*.jpg').take(3000)\n",
        "positive=tf.data.Dataset.list_files('/content/data/positive/'+'*.jpg').take(3000)\n",
        "negative=tf.data.Dataset.list_files('/content/data/negative/'+'*.jpg').take(3000)"
      ],
      "metadata": {
        "id": "o_W2TiPbrMj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_test=anchor.as_numpy_iterator()\n",
        "dir_test.next()"
      ],
      "metadata": {
        "id": "AtZoNFzLrqft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cccd8adf-7430-4b9d-f033-e91e58bd7757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'/content/data/anchor/a690414c-e9d0-11ed-970e-0242ac1c000c.jpg'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(file_path):\n",
        "  #Read in image from file path\n",
        "  byte_img=tf.io.read_file(file_path)\n",
        "  #Load in the image\n",
        "  img=tf.io.decode_jpeg(byte_img)\n",
        "  img=tf.image.resize(img,(100,100))\n",
        "  img=img/255.0\n",
        "  return img"
      ],
      "metadata": {
        "id": "z_fCPNjsvS3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create Labelled Dataset"
      ],
      "metadata": {
        "id": "5NIMb2e1xgOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positives=tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "##tensor_slices converts tf.ones(len(anchor)) into same datatype as anchor and positive(tf.data.Dataset files)\n",
        "negatives=tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
        "data=positives.concatenate(negatives)"
      ],
      "metadata": {
        "id": "LmMXJyOAxiUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "Ou2YALI8y0nr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe531f1-78ad-4638-e3bc-830dcf3dd2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_ConcatenateDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples=data.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "cV2lqDTJBvgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example=samples.next()"
      ],
      "metadata": {
        "id": "J7geYAvJCSC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6qkRg73Cs8n",
        "outputId": "0fd9399d-4f72-4da3-eddb-5a3d72c3aa74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(b'/content/data/anchor/ab0900ba-e9d0-11ed-970e-0242ac1c000c.jpg',\n",
              " b'/content/data/positive/8afc4098-e9d0-11ed-970e-0242ac1c000c.jpg',\n",
              " 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train and Test Partition"
      ],
      "metadata": {
        "id": "8Ijyok5fy6_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_twin(input_img,validation_img,label):\n",
        "  return (preprocess(input_img),preprocess(validation_img),label)"
      ],
      "metadata": {
        "id": "5FF7U-mjy7s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '*' is used to unpack the values\n",
        "res=preprocess_twin(*example)"
      ],
      "metadata": {
        "id": "cFYo9ZqWCkWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y0Gm75XDG_l",
        "outputId": "8a507f4d-f81d-45fa-d5f9-2836ee710831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
              "array([[[0.65612745, 0.7463235 , 0.714951  ],\n",
              "        [0.66838235, 0.7507353 , 0.7232843 ],\n",
              "        [0.68063724, 0.76004905, 0.7267157 ],\n",
              "        ...,\n",
              "        [0.66519606, 0.75147057, 0.7436274 ],\n",
              "        [0.6514706 , 0.7348039 , 0.7357843 ],\n",
              "        [0.6607843 , 0.74313724, 0.7470588 ]],\n",
              "\n",
              "       [[0.65294117, 0.7352941 , 0.70980394],\n",
              "        [0.6698529 , 0.75171566, 0.7245098 ],\n",
              "        [0.67745095, 0.7534314 , 0.7291667 ],\n",
              "        ...,\n",
              "        [0.6970588 , 0.78063726, 0.7759804 ],\n",
              "        [0.6897059 , 0.76887256, 0.7708333 ],\n",
              "        [0.6872549 , 0.7637255 , 0.76862746]],\n",
              "\n",
              "       [[0.66568625, 0.74215686, 0.7254902 ],\n",
              "        [0.6637255 , 0.73970586, 0.7198529 ],\n",
              "        [0.675     , 0.74509805, 0.72156864],\n",
              "        ...,\n",
              "        [0.6620098 , 0.7375    , 0.73063725],\n",
              "        [0.685049  , 0.76053923, 0.7536765 ],\n",
              "        [0.68921566, 0.7627451 , 0.75686276]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.5882353 , 0.6607843 , 0.60784316],\n",
              "        [0.59313726, 0.6578431 , 0.60784316],\n",
              "        [0.60318625, 0.66789216, 0.61789215],\n",
              "        ...,\n",
              "        [0.27034312, 0.4625    , 0.48406863],\n",
              "        [0.26691177, 0.45906863, 0.48063725],\n",
              "        [0.24313726, 0.43529412, 0.45686275]],\n",
              "\n",
              "       [[0.5852941 , 0.6637255 , 0.6166667 ],\n",
              "        [0.59632355, 0.6786765 , 0.63014704],\n",
              "        [0.610049  , 0.69436276, 0.64730394],\n",
              "        ...,\n",
              "        [0.39019608, 0.5764706 , 0.60245097],\n",
              "        [0.2007353 , 0.3870098 , 0.41740197],\n",
              "        [0.19019608, 0.3764706 , 0.40686274]],\n",
              "\n",
              "       [[0.60588235, 0.69215685, 0.64117646],\n",
              "        [0.64117646, 0.7294118 , 0.6784314 ],\n",
              "        [0.6458333 , 0.7392157 , 0.69779414],\n",
              "        ...,\n",
              "        [0.5620098 , 0.7502451 , 0.76593137],\n",
              "        [0.6237745 , 0.8098039 , 0.82990193],\n",
              "        [0.5781863 , 0.7625    , 0.7860294 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(res[0])"
      ],
      "metadata": {
        "id": "E6MyxUMqCy-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Pipeline"
      ],
      "metadata": {
        "id": "RVHhm-MpVGcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.map(preprocess_twin)\n",
        "data=data.cache()\n",
        "data=data.shuffle(buffer_size=10000)"
      ],
      "metadata": {
        "id": "10PsxEHZVIzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlnBe8cjW6-C",
        "outputId": "e7abdd28-56c4-433f-bfc5-06fbb22da437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_ShuffleDataset element_spec=(TensorSpec(shape=(100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ele=data.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "KV5fQbSGby9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample=ele.next()"
      ],
      "metadata": {
        "id": "0w_JLcmkdHM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(sample[1])"
      ],
      "metadata": {
        "id": "7F4cNr2EdF2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_JOb5QUdLEq",
        "outputId": "992b2ec2-26dc-4e99-f14d-873be8148623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training and Test Partition"
      ],
      "metadata": {
        "id": "Sl02GxzVejLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training partition\n",
        "train_data = data.take(round(len(data)*.7))\n",
        "train_data = train_data.batch(16)\n",
        "train_data = train_data.prefetch(8)"
      ],
      "metadata": {
        "id": "TfIe94rdentf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = data.skip(round(len(data)*.7))\n",
        "test_data = test_data.take(round(len(data)*.3))\n",
        "test_data = test_data.batch(16)\n",
        "test_data = test_data.prefetch(8)"
      ],
      "metadata": {
        "id": "bGUbnWY0eqGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data),len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8YtYRIpeqlh",
        "outputId": "ef85721c-ce1f-46ed-ecf8-b9218f83033f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(263, 113)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building Siamese Neural Network"
      ],
      "metadata": {
        "id": "HCJUFYTZjEWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Embedding Layer"
      ],
      "metadata": {
        "id": "373noe-ykLM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_embedding():\n",
        "  inp=Input(shape=(100,100,3),name='input_image')\n",
        "\n",
        "  #First Block\n",
        "  c1=Conv2D(64,(10,10),activation='relu')(inp)\n",
        "  m1=MaxPooling2D(64,(2,2),padding='same')(c1)\n",
        "\n",
        "  #Second Block\n",
        "  c2=Conv2D(128,(7,7),activation='relu')(m1)\n",
        "  m2=MaxPooling2D(64,(2,2),padding='same')(c2)\n",
        "\n",
        "  #Third Block\n",
        "  c3=Conv2D(128,(4,4),activation='relu')(m2)\n",
        "  m3=MaxPooling2D(64,(2,2),padding='same')(c3)\n",
        "\n",
        "  #Final Embedding Block\n",
        "  c4=Conv2D(256,(4,4),activation='relu')(m3)\n",
        "  f1=Flatten()(c4)\n",
        "  d1=Dense(4096,activation='sigmoid')(f1)\n",
        "\n",
        "  return Model(inputs=[inp],outputs=[d1],name='embedding')"
      ],
      "metadata": {
        "id": "Gtn1ZCqEkNge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding=make_embedding()"
      ],
      "metadata": {
        "id": "rqpIGhPEpNj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlB1Tw844puE",
        "outputId": "2b8a7f4a-75bd-463d-d5eb-c5df1e8f8b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"embedding\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_image (InputLayer)    [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 91, 91, 64)        19264     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 46, 46, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 40, 40, 128)       401536    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 20, 20, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 17, 17, 128)       262272    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 9, 9, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              37752832  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,960,448\n",
            "Trainable params: 38,960,448\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Distance Layer"
      ],
      "metadata": {
        "id": "LIfsgSpzmejU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class L1Dist(Layer):\n",
        "  def __init__(self,**kwargs):\n",
        "    super().__init__()\n",
        "\n",
        "  def call(self,input_embedding,validation_embedding):\n",
        "    return tf.math.abs(input_embedding - validation_embedding)"
      ],
      "metadata": {
        "id": "VeRXc-ujmg3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L1Dist=L1Dist()"
      ],
      "metadata": {
        "id": "gtGCSNblpaLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Siamese Model"
      ],
      "metadata": {
        "id": "L0-0Gs1OoYw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_siamese_model():\n",
        "  #Handle input\n",
        "  input_image=Input(name='input_img',shape=(100,100,3))\n",
        "  validation_image=Input(name='validation_img',shape=(100,100,3))\n",
        "\n",
        "  #Building siamese network components\n",
        "  siamese_layer=L1Dist\n",
        "  siamese_layer._name='distance'\n",
        "  distances=siamese_layer(embedding(input_image),embedding(validation_image))\n",
        "\n",
        "  #Classification Layer\n",
        "  classifier=Dense(1,activation='sigmoid')(distances)\n",
        "\n",
        "  return Model(inputs=[input_image,validation_image],outputs=classifier,name='SiameseNetwork')\n"
      ],
      "metadata": {
        "id": "J2WIvypioiol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model=make_siamese_model()"
      ],
      "metadata": {
        "id": "dgmCjXRT35PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykFilMTG514h",
        "outputId": "eb4f079c-94a7-4600-af23-72acc489184d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"SiameseNetwork\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_img (InputLayer)         [(None, 100, 100, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " validation_img (InputLayer)    [(None, 100, 100, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " embedding (Functional)         (None, 4096)         38960448    ['input_img[0][0]',              \n",
            "                                                                  'validation_img[0][0]']         \n",
            "                                                                                                  \n",
            " distance (L1Dist)              (None, 4096)         0           ['embedding[0][0]',              \n",
            "                                                                  'embedding[1][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            4097        ['distance[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38,964,545\n",
            "Trainable params: 38,964,545\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "bstRyx4hn89h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Loss and Optimizer\n",
        "binary_cross_loss=tf.losses.BinaryCrossentropy()\n",
        "opt=tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "79l7mzRbn_EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checkpoints\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
      ],
      "metadata": {
        "id": "FPjxCcJR8t-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(batch):\n",
        "  '''\n",
        "  This function focuses on training a singlr batch\n",
        "  '''\n",
        "  with tf.GradientTape() as tape:\n",
        "    #Get anchor and positive/negative images\n",
        "    X=batch[:2]\n",
        "    #Get label\n",
        "    Y=batch[2]\n",
        "    #Forward pass\n",
        "    yhat=siamese_model(X,training=True)\n",
        "    #Calculate loss\n",
        "    loss=binary_cross_loss(Y,yhat)\n",
        "  print(loss)\n",
        "  #Calculate Gradients\n",
        "  grad=tape.gradient(loss,siamese_model.trainable_variables)\n",
        "\n",
        "  #Calculate updated weights and apply to siamese model\n",
        "  opt.apply_gradients(zip(grad,siamese_model.trainable_variables))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "1v1T7irZ9S3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import metric calculations\n",
        "from tensorflow.keras.metrics import Precision, Recall"
      ],
      "metadata": {
        "id": "RhpO9kXfvNZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data, EPOCHS):\n",
        "    # Loop through epochs\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
        "        progbar = tf.keras.utils.Progbar(len(data))\n",
        "\n",
        "        # Creating a metric object\n",
        "        r = Recall()\n",
        "        p = Precision()\n",
        "\n",
        "        # Loop through each batch\n",
        "        for idx, batch in enumerate(data):\n",
        "            # Run train step here\n",
        "            loss = train_step(batch)\n",
        "            yhat = siamese_model.predict(batch[:2])\n",
        "            r.update_state(batch[2], yhat)\n",
        "            p.update_state(batch[2], yhat)\n",
        "            progbar.update(idx+1)\n",
        "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
        "\n",
        "        # Save checkpoints\n",
        "        if epoch % 10 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)"
      ],
      "metadata": {
        "id": "Zjs6S05RqTir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=5"
      ],
      "metadata": {
        "id": "ZQ_uBPWqvvX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_data,EPOCHS)"
      ],
      "metadata": {
        "id": "u3pnzbxSv9Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluate Model"
      ],
      "metadata": {
        "id": "R1QERKuA4kqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import Precision,Recall"
      ],
      "metadata": {
        "id": "IfCQ-Udb4mf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting a batch of test data\n",
        "test_input,test_val,y_true=test_data.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "o6OXSSiT4-zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making Predictions\n",
        "yhat=siamese_model.predict([test_input,test_val])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwMoWrO35_zQ",
        "outputId": "60b68e0a-5d14-4124-d235-0311d5b9082b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 44ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LSP0pBN6THJ",
        "outputId": "d974e0ac-21dd-4689-95dc-6765280005c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.3647328e-06],\n",
              "       [1.0000000e+00],\n",
              "       [2.1215435e-05],\n",
              "       [9.9502891e-01],\n",
              "       [1.9056566e-08],\n",
              "       [9.9984276e-01],\n",
              "       [2.0317341e-06],\n",
              "       [9.9986219e-01],\n",
              "       [5.9283258e-07],\n",
              "       [3.0470394e-05],\n",
              "       [5.0404535e-05],\n",
              "       [6.8875946e-05],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.9999189e-01],\n",
              "       [9.9999857e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Post-Processing the results\n",
        "[1 if prediction>0.5 else 0 for prediction in yhat]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l741ZV1N6zNS",
        "outputId": "0c078e13-b069-4820-ae37-6cb2fdc03c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M21GVJi7I19",
        "outputId": "2f91a52e-16bc-4691-c263-cead2b02d38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Recall-Measures how many actual positives are correctly predicted by model\n",
        "\n",
        "#Creating a Metric Object\n",
        "m=Recall()\n",
        "#Calculating Recall Value\n",
        "m.update_state(y_true,yhat)\n",
        "#Return Recall Result\n",
        "m.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIGc6dch7Vdu",
        "outputId": "66fab5f9-e63e-4b88-c352-8e8cf339639b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Precision-Measures how many of the predicted positive instances are actually positive\n",
        "\n",
        "p=Precision()\n",
        "p.update_state(y_true,yhat)\n",
        "p.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4oj49g57zkn",
        "outputId": "2a5ebb41-270b-4176-f998-70692b84e4b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = Recall()\n",
        "p = Precision()\n",
        "\n",
        "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
        "    yhat = siamese_model.predict([test_input, test_val])\n",
        "    r.update_state(y_true, yhat)\n",
        "    p.update_state(y_true,yhat)\n",
        "\n",
        "print(r.result().numpy(), p.result().numpy())"
      ],
      "metadata": {
        "id": "-W0vQoAIiqNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Visualise Results"
      ],
      "metadata": {
        "id": "Eyz5pqDS9REC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(test_input[0])\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(test_val[0])"
      ],
      "metadata": {
        "id": "pMjRHAsQ9TFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save Model"
      ],
      "metadata": {
        "id": "w4T3l4W7_Dfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model.save('siamese_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POJVU_zS_Fjk",
        "outputId": "a0a71478-07c1-46cc-c6c9-d8f51c45f387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Model\n",
        "siamese_model = tf.keras.models.load_model('/content/siamese_model.h5',\n",
        "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAlAYlt-_VNe",
        "outputId": "f2430ee2-c3dc-4177-878f-0833b8797a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Real Time Test"
      ],
      "metadata": {
        "id": "P9fHIxrreuex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify(model,detection_threshold,verification_threshold):\n",
        "  '''\n",
        "  Detection Threhold-Metric above which image is considered positive\n",
        "  Verification Threhold-Proportion of positive predictions/total positive samples\n",
        "  '''\n",
        "  results=[]\n",
        "  for image in os.listdir(os.path.join('application_data','verification_images')):\n",
        "    input_img=preprocess(os.path.join('application_data','input_images','input_image.jpg'))\n",
        "    validation_img=preprocess(os.path.join('application_data','verification_images',image))\n",
        "\n",
        "    result=model.predict(list(np.expand_dims([input_img,verification_threshold],axis=1)))\n",
        "    results.append(result)\n",
        "\n",
        "  detection=np.sum(np.array(results)>detection_threshold)\n",
        "  verification=detection/len(os.listdir(os.path.join('application_data','verification_images')))\n",
        "  verified=verification>verification_threshold\n",
        "  return verified"
      ],
      "metadata": {
        "id": "iNsLMMrKewQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(4)\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    frame = frame[120:120+250,200:200+250, :]\n",
        "\n",
        "    cv2.imshow('Verification', frame)\n",
        "\n",
        "    # Verification trigger\n",
        "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
        "        cv2.imwrite(os.path.join('application_data', 'input_image', 'input_image.jpg'), frame)\n",
        "        # Run verification\n",
        "        results, verified = verify(siamese_model, 0.9, 0.7)\n",
        "        print(verified)\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "lYmGt_Mbmn44"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyQNrfIswz3HtXWbZYks0Y",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}