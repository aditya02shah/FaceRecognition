{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya02shah/FaceRecognition/blob/main/FaceRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XP92HM7W4c3"
      },
      "source": [
        "##Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lOqkvKyYW6T9"
      },
      "outputs": [],
      "source": [
        "#Standard Dependancies\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kNhM1XZlXGic"
      },
      "outputs": [],
      "source": [
        "##Tensorflow dependencies-Functional API\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense,Layer,Conv2D,MaxPooling2D,Input,Flatten\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "X_UEoHeWX4Qq"
      },
      "outputs": [],
      "source": [
        "POS_PATH=os.path.join('data','positive')\n",
        "NEG_PATH=os.path.join('data','negative')\n",
        "ANC_PATH=os.path.join('data','anchor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoERDBaxhNvi"
      },
      "outputs": [],
      "source": [
        "os.makedirs(POS_PATH)\n",
        "os.makedirs(NEG_PATH)\n",
        "os.makedirs(ANC_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8NjIa231PqR"
      },
      "source": [
        "##Collecting Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw8a3pOD1TpC",
        "outputId": "1d154926-f941-43fa-866e-ec532500b4b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-21 03:28:08--  http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
            "Resolving vis-www.cs.umass.edu (vis-www.cs.umass.edu)... 128.119.244.95\n",
            "Connecting to vis-www.cs.umass.edu (vis-www.cs.umass.edu)|128.119.244.95|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180566744 (172M) [application/x-gzip]\n",
            "Saving to: ‘lfw.tgz’\n",
            "\n",
            "lfw.tgz             100%[===================>] 172.20M  55.4MB/s    in 3.3s    \n",
            "\n",
            "2023-04-21 03:28:12 (52.3 MB/s) - ‘lfw.tgz’ saved [180566744/180566744]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"http://vis-www.cs.umass.edu/lfw/lfw.tgz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEQckVjJ1qk7"
      },
      "outputs": [],
      "source": [
        "##Uncompress Tar GZ Labelled Faces in the wild Dataset\n",
        "!tar -xf lfw.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKIV2cJM2F7e"
      },
      "outputs": [],
      "source": [
        "#Moving lfw images to data/negative\n",
        "for directory in os.listdir('lfw'):\n",
        "  for filename in os.listdir(os.path.join('lfw',directory)):\n",
        "    CUR_PATH=os.path.join('lfw',directory,filename)\n",
        "    NEW_PATH=os.path.join(NEG_PATH,filename)\n",
        "    os.replace(CUR_PATH,NEW_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAVVmcRR6tyv"
      },
      "source": [
        "##Collect Positives and Anchors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid"
      ],
      "metadata": {
        "id": "JcvaIzB7on_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HxrQW0zWA8Z"
      },
      "outputs": [],
      "source": [
        "#Establish a connection to the webcam\n",
        "cap=cv2.VideoCapture(3)\n",
        "while cap.isOpened():\n",
        "  ret,frame=cap.read()\n",
        "\n",
        "  frame=frame[120:120+250,200:200+250,:]\n",
        "  #Show image back to screen\n",
        "  cv2.imshow(\"Image Collection\",frame)\n",
        "\n",
        "  #Collecting Anchors\n",
        "  if cv2.waitKey(1) & 0XFF == ord('a'):\n",
        "    imgname=os.path.join(ANC_PATH,'{}.jpg'.format(uuid.uuid1()))\n",
        "    cv2.imwrite(imgname,frame)\n",
        "  #Collecting Positives\n",
        "  if cv2.waitKey(1) & 0XFF == ord('p'):\n",
        "    imgname=os.path.join(POS_PATH,'{}.jpg'.format(uuid.uuid1()))\n",
        "    cv2.imwrite(imgname,frame)\n",
        "\n",
        "  #Breaking gracefull\n",
        "  if cv2.waitKey(1) & 0XFF == ord('q'):\n",
        "    break\n",
        "\n",
        "#Release the webcam\n",
        "cap.release()\n",
        "#Close the image show frame\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh5WIzsRYNoj"
      },
      "outputs": [],
      "source": [
        "cap.read??"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hL30fzbIrDck",
        "outputId": "3cb84daa-f448-4d9d-deb9-da57ba530c09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/gdrive/MyDrive/ML/data.zip'"
      ],
      "metadata": {
        "id": "FUfYy8lV-TRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pre-processing Data"
      ],
      "metadata": {
        "id": "oSFgiwvprIJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anchor=tf.data.Dataset.list_files('/content/data/anchor/'+'*.jpg').take(300)\n",
        "positive=tf.data.Dataset.list_files('/content/data/positive/'+'*.jpg').take(300)\n",
        "negative=tf.data.Dataset.list_files('/content/data/negative/'+'*.jpg').take(300)"
      ],
      "metadata": {
        "id": "o_W2TiPbrMj_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_test=anchor.as_numpy_iterator()\n",
        "dir_test.next()"
      ],
      "metadata": {
        "id": "AtZoNFzLrqft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774ee51f-cfc3-4b8c-e710-a7776ac97d1e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'/content/data/anchor/8ea10020-deb2-11ed-a860-089798716103.jpg'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(file_path):\n",
        "  #Read in image from file path\n",
        "  byte_img=tf.io.read_file(file_path)\n",
        "  #Load in the image\n",
        "  img=tf.io.decode_jpeg(byte_img)\n",
        "  img=tf.image.resize(img,(100,100))\n",
        "  img=img/255.0\n",
        "  return img"
      ],
      "metadata": {
        "id": "z_fCPNjsvS3n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create Labelled Dataset"
      ],
      "metadata": {
        "id": "5NIMb2e1xgOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positives=tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "##tensor_slices converts tf.ones(len(anchor)) into same datatype as anchor and positive(tf.data.Dataset files)\n",
        "negatives=tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
        "data=positives.concatenate(negatives)"
      ],
      "metadata": {
        "id": "LmMXJyOAxiUl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "Ou2YALI8y0nr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb76bfa-4778-4ecd-97c8-c7a14692702e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_ConcatenateDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples=data.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "cV2lqDTJBvgR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example=samples.next()"
      ],
      "metadata": {
        "id": "J7geYAvJCSC1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6qkRg73Cs8n",
        "outputId": "93ec092e-4eff-428c-fa24-3b38dfa4a012"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(b'/content/data/anchor/8d9fdfb9-deb2-11ed-9dca-089798716103.jpg',\n",
              " b'/content/data/positive/fa648255-deb2-11ed-a51f-089798716103.jpg',\n",
              " 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train and Test Partition"
      ],
      "metadata": {
        "id": "8Ijyok5fy6_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_twin(input_img,validation_img,label):  \n",
        "  return (preprocess(input_img),preprocess(validation_img),label)"
      ],
      "metadata": {
        "id": "5FF7U-mjy7s7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# '*' is used to unpack the values\n",
        "res=preprocess_twin(*example)"
      ],
      "metadata": {
        "id": "cFYo9ZqWCkWe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y0Gm75XDG_l",
        "outputId": "72005d70-77e7-458c-a1e3-02ab4891d8c8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
              "array([[[6.9436276e-01, 7.4926472e-01, 7.5318629e-01],\n",
              "        [6.9828433e-01, 7.5318629e-01, 7.5710785e-01],\n",
              "        [7.0122552e-01, 7.5612748e-01, 7.6004905e-01],\n",
              "        ...,\n",
              "        [6.8897057e-01, 7.5955880e-01, 8.0661762e-01],\n",
              "        [6.9044119e-01, 7.5588238e-01, 8.0367649e-01],\n",
              "        [6.8382353e-01, 7.5049019e-01, 7.8970587e-01]],\n",
              "\n",
              "       [[6.9803923e-01, 7.5294119e-01, 7.5588238e-01],\n",
              "        [6.9117647e-01, 7.4607843e-01, 7.4901962e-01],\n",
              "        [6.9975489e-01, 7.5465685e-01, 7.5759804e-01],\n",
              "        ...,\n",
              "        [7.1004903e-01, 7.8455883e-01, 8.3946079e-01],\n",
              "        [7.0563728e-01, 7.7720588e-01, 8.2622552e-01],\n",
              "        [7.0661765e-01, 7.7720588e-01, 8.2426471e-01]],\n",
              "\n",
              "       [[6.8308824e-01, 7.3799020e-01, 7.3799020e-01],\n",
              "        [6.7745095e-01, 7.3235291e-01, 7.3235291e-01],\n",
              "        [6.8823528e-01, 7.4313724e-01, 7.4313724e-01],\n",
              "        ...,\n",
              "        [6.9240195e-01, 7.6372552e-01, 8.0416667e-01],\n",
              "        [7.0147061e-01, 7.6911765e-01, 8.1029409e-01],\n",
              "        [7.0980394e-01, 7.7745098e-01, 8.1078434e-01]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[6.1274511e-01, 6.2034315e-01, 5.6544119e-01],\n",
              "        [6.0808825e-01, 6.2500000e-01, 5.7475489e-01],\n",
              "        [5.8357841e-01, 6.1470586e-01, 5.7524508e-01],\n",
              "        ...,\n",
              "        [3.6029413e-02, 3.1642157e-01, 4.1249999e-01],\n",
              "        [6.6176474e-02, 3.2965687e-01, 4.1985294e-01],\n",
              "        [6.3725494e-02, 3.0490196e-01, 3.9803922e-01]],\n",
              "\n",
              "       [[5.9338236e-01, 6.2475491e-01, 5.7745099e-01],\n",
              "        [5.7941175e-01, 6.3823527e-01, 5.9901959e-01],\n",
              "        [5.6102943e-01, 6.4730394e-01, 6.2671566e-01],\n",
              "        ...,\n",
              "        [3.7745100e-02, 3.0245098e-01, 4.1029412e-01],\n",
              "        [1.0539216e-02, 2.5049019e-01, 3.6715686e-01],\n",
              "        [8.5784318e-03, 2.3725490e-01, 3.5882354e-01]],\n",
              "\n",
              "       [[5.7524508e-01, 6.5955883e-01, 6.3382351e-01],\n",
              "        [6.1200982e-01, 7.3039216e-01, 7.1519607e-01],\n",
              "        [5.6446081e-01, 7.2132355e-01, 7.1813726e-01],\n",
              "        ...,\n",
              "        [3.9191177e-01, 6.4681375e-01, 7.2524512e-01],\n",
              "        [5.3431373e-02, 2.6568627e-01, 3.7181371e-01],\n",
              "        [7.3529413e-04, 2.0098040e-01, 3.3431372e-01]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(res[0])"
      ],
      "metadata": {
        "id": "E6MyxUMqCy-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Pipeline"
      ],
      "metadata": {
        "id": "RVHhm-MpVGcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.map(preprocess_twin)\n",
        "data=data.cache()\n",
        "data=data.shuffle(buffer_size=1024)"
      ],
      "metadata": {
        "id": "10PsxEHZVIzD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlnBe8cjW6-C",
        "outputId": "4d004c58-244c-4dba-d562-d687d31390ed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_ShuffleDataset element_spec=(TensorSpec(shape=(100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(100, 100, None), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ele=data.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "KV5fQbSGby9q"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample=ele.next()"
      ],
      "metadata": {
        "id": "0w_JLcmkdHM9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(sample[1])"
      ],
      "metadata": {
        "id": "7F4cNr2EdF2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_JOb5QUdLEq",
        "outputId": "225ecdc6-21ca-48ea-fe17-092cde1eb999"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training and Test Partition"
      ],
      "metadata": {
        "id": "Sl02GxzVejLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training partition\n",
        "train_data = data.take(round(len(data)*.7))\n",
        "train_data = train_data.batch(16)\n",
        "train_data = train_data.prefetch(8)"
      ],
      "metadata": {
        "id": "TfIe94rdentf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = data.skip(round(len(data)*.7))\n",
        "test_data = test_data.take(round(len(data)*.3))\n",
        "test_data = test_data.batch(16)\n",
        "test_data = test_data.prefetch(8)"
      ],
      "metadata": {
        "id": "bGUbnWY0eqGv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data),len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8YtYRIpeqlh",
        "outputId": "5b6f7066-8aaf-422b-f1b6-ad89cf6a70b3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building Siamese Neural Network"
      ],
      "metadata": {
        "id": "HCJUFYTZjEWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Embedding Layer"
      ],
      "metadata": {
        "id": "373noe-ykLM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_embedding():\n",
        "  inp=Input(shape=(100,100,3),name='input_image')\n",
        "\n",
        "  #First Block\n",
        "  c1=Conv2D(64,(10,10),activation='relu')(inp)\n",
        "  m1=MaxPooling2D(64,(2,2),padding='same')(c1)\n",
        "\n",
        "  #Second Block\n",
        "  c2=Conv2D(128,(7,7),activation='relu')(m1)\n",
        "  m2=MaxPooling2D(64,(2,2),padding='same')(c2)\n",
        "\n",
        "  #Third Block\n",
        "  c3=Conv2D(128,(4,4),activation='relu')(m2)\n",
        "  m3=MaxPooling2D(64,(2,2),padding='same')(c3)\n",
        "\n",
        "  #Final Embedding Block\n",
        "  c4=Conv2D(256,(4,4),activation='relu')(m3)\n",
        "  f1=Flatten()(c4)\n",
        "  d1=Dense(4096,activation='sigmoid')(f1)\n",
        "\n",
        "  return Model(inputs=[inp],outputs=[d1],name='embedding')"
      ],
      "metadata": {
        "id": "Gtn1ZCqEkNge"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding=make_embedding()"
      ],
      "metadata": {
        "id": "rqpIGhPEpNj8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlB1Tw844puE",
        "outputId": "4ecd9e7d-8fdb-495a-8c33-c54997193ac6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"embedding\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_image (InputLayer)    [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 91, 91, 64)        19264     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 46, 46, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 40, 40, 128)       401536    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 20, 20, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 17, 17, 128)       262272    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 9, 9, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              37752832  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,960,448\n",
            "Trainable params: 38,960,448\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Distance Layer"
      ],
      "metadata": {
        "id": "LIfsgSpzmejU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class L1Dist(Layer):\n",
        "  def __init__(self,**kwargs):\n",
        "    super().__init__()\n",
        "\n",
        "  def call(self,input_embedding,validation_embedding):\n",
        "    return tf.math.abs(input_embedding - validation_embedding)"
      ],
      "metadata": {
        "id": "VeRXc-ujmg3i"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L1Dist=L1Dist()"
      ],
      "metadata": {
        "id": "gtGCSNblpaLm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Siamese Model"
      ],
      "metadata": {
        "id": "L0-0Gs1OoYw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_siamese_model():\n",
        "  #Handle input\n",
        "  input_image=Input(name='input_img',shape=(100,100,3))\n",
        "  validation_image=Input(name='validation_img',shape=(100,100,3))\n",
        "\n",
        "  #Building siamese network components\n",
        "  siamese_layer=L1Dist\n",
        "  siamese_layer._name='distance'\n",
        "  distances=siamese_layer(embedding(input_image),embedding(validation_image))\n",
        "\n",
        "  #Classification Layer\n",
        "  classifier=Dense(1,activation='sigmoid')(distances)\n",
        "\n",
        "  return Model(inputs=[input_image,validation_image],outputs=classifier,name='SiameseNetwork')\n"
      ],
      "metadata": {
        "id": "J2WIvypioiol"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model=make_siamese_model()"
      ],
      "metadata": {
        "id": "dgmCjXRT35PA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykFilMTG514h",
        "outputId": "14c7b68d-d960-48e1-dae1-c35cf3dd915d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"SiameseNetwork\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_img (InputLayer)         [(None, 100, 100, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " validation_img (InputLayer)    [(None, 100, 100, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " embedding (Functional)         (None, 4096)         38960448    ['input_img[0][0]',              \n",
            "                                                                  'validation_img[0][0]']         \n",
            "                                                                                                  \n",
            " distance (L1Dist)              (None, 4096)         0           ['embedding[0][0]',              \n",
            "                                                                  'embedding[1][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            4097        ['distance[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38,964,545\n",
            "Trainable params: 38,964,545\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "bstRyx4hn89h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Loss and Optimizer\n",
        "binary_cross_loss=tf.losses.BinaryCrossentropy()\n",
        "opt=tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "79l7mzRbn_EH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checkpoints\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
      ],
      "metadata": {
        "id": "FPjxCcJR8t-l"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(batch):\n",
        "  '''\n",
        "  This function focuses on training a singlr batch\n",
        "  '''\n",
        "  with tf.GradientTape() as tape:\n",
        "    #Get anchor and positive/negative images\n",
        "    X=batch[:2]\n",
        "    #Get label\n",
        "    Y=batch[2]\n",
        "    #Forward pass\n",
        "    yhat=siamese_model(X,training=True)\n",
        "    #Calculate loss\n",
        "    loss=binary_cross_loss(Y,yhat)\n",
        "  print(loss)\n",
        "  #Calculate Gradients\n",
        "  grad=tape.gradient(loss,siamese_model.trainable_variables)\n",
        "\n",
        "  #Calculate updated weights and apply to siamese model\n",
        "  opt.apply_gradients(zip(grad,siamese_model.trainable_variables))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "1v1T7irZ9S3x"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data,EPOCHS):\n",
        "  '''\n",
        "  This function is used iterate over every batch in the dataset\n",
        "  '''\n",
        "  #Loop through epochs\n",
        "  for epoch in range(1,EPOCHS+1):\n",
        "    print(\"EPOCH {}/{}\".format(epoch,EPOCHS))\n",
        "    progbar=tf.keras.utils.Progbar(len(data))\n",
        "\n",
        "    #Loop through each batch\n",
        "    for idx,batch in enumerate(data):\n",
        "      #Run train step here\n",
        "      train_step(batch)\n",
        "      progbar.update(idx+1)\n",
        "    \n",
        "    #Save checkpoints\n",
        "    if epoch%10==0:\n",
        "      checkpoint.save(file_prefix=checkpoint_prefix)"
      ],
      "metadata": {
        "id": "Zjs6S05RqTir"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=50"
      ],
      "metadata": {
        "id": "ZQ_uBPWqvvX-"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_data,EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3pnzbxSv9Px",
        "outputId": "1ee144ed-99ca-481f-f755-a0fc3ab67cb8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1/50\n",
            "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
            "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
            "26/27 [===========================>..] - ETA: 0sTensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
            "27/27 [==============================] - 18s 202ms/step\n",
            "EPOCH 2/50\n",
            "27/27 [==============================] - 5s 183ms/step\n",
            "EPOCH 3/50\n",
            "27/27 [==============================] - 5s 183ms/step\n",
            "EPOCH 4/50\n",
            "27/27 [==============================] - 5s 183ms/step\n",
            "EPOCH 5/50\n",
            "27/27 [==============================] - 5s 186ms/step\n",
            "EPOCH 6/50\n",
            "27/27 [==============================] - 5s 186ms/step\n",
            "EPOCH 7/50\n",
            "27/27 [==============================] - 5s 186ms/step\n",
            "EPOCH 8/50\n",
            "27/27 [==============================] - 5s 185ms/step\n",
            "EPOCH 9/50\n",
            "27/27 [==============================] - 5s 186ms/step\n",
            "EPOCH 10/50\n",
            "27/27 [==============================] - 5s 188ms/step\n",
            "EPOCH 11/50\n",
            "27/27 [==============================] - 5s 193ms/step\n",
            "EPOCH 12/50\n",
            "27/27 [==============================] - 5s 189ms/step\n",
            "EPOCH 13/50\n",
            "27/27 [==============================] - 5s 189ms/step\n",
            "EPOCH 14/50\n",
            "27/27 [==============================] - 5s 189ms/step\n",
            "EPOCH 15/50\n",
            "27/27 [==============================] - 5s 191ms/step\n",
            "EPOCH 16/50\n",
            "27/27 [==============================] - 5s 191ms/step\n",
            "EPOCH 17/50\n",
            "27/27 [==============================] - 5s 193ms/step\n",
            "EPOCH 18/50\n",
            "27/27 [==============================] - 5s 193ms/step\n",
            "EPOCH 19/50\n",
            "27/27 [==============================] - 5s 193ms/step\n",
            "EPOCH 20/50\n",
            "27/27 [==============================] - 5s 193ms/step\n",
            "EPOCH 21/50\n",
            "27/27 [==============================] - 5s 193ms/step\n",
            "EPOCH 22/50\n",
            "27/27 [==============================] - 5s 195ms/step\n",
            "EPOCH 23/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 24/50\n",
            "27/27 [==============================] - 5s 197ms/step\n",
            "EPOCH 25/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 26/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 27/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 28/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 29/50\n",
            "27/27 [==============================] - 5s 197ms/step\n",
            "EPOCH 30/50\n",
            "27/27 [==============================] - 5s 200ms/step\n",
            "EPOCH 31/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 32/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 33/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 34/50\n",
            "27/27 [==============================] - 5s 197ms/step\n",
            "EPOCH 35/50\n",
            "27/27 [==============================] - 5s 199ms/step\n",
            "EPOCH 36/50\n",
            "27/27 [==============================] - 5s 198ms/step\n",
            "EPOCH 37/50\n",
            "27/27 [==============================] - 5s 197ms/step\n",
            "EPOCH 38/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 39/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 40/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 41/50\n",
            "27/27 [==============================] - 5s 195ms/step\n",
            "EPOCH 42/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 43/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 44/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 45/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 46/50\n",
            "27/27 [==============================] - 5s 197ms/step\n",
            "EPOCH 47/50\n",
            "27/27 [==============================] - 5s 197ms/step\n",
            "EPOCH 48/50\n",
            "27/27 [==============================] - 5s 200ms/step\n",
            "EPOCH 49/50\n",
            "27/27 [==============================] - 5s 196ms/step\n",
            "EPOCH 50/50\n",
            "27/27 [==============================] - 5s 197ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluate Model"
      ],
      "metadata": {
        "id": "R1QERKuA4kqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import Precision,Recall"
      ],
      "metadata": {
        "id": "IfCQ-Udb4mf6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting a batch of test data\n",
        "test_input,test_val,y_true=test_data.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "o6OXSSiT4-zf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making Predictions\n",
        "yhat=siamese_model.predict([test_input,test_val])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwMoWrO35_zQ",
        "outputId": "e7e18666-77a3-43d3-8cbc-ad48d5783212"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 168ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LSP0pBN6THJ",
        "outputId": "c961a7cc-91bd-42bd-8fe9-32f5ecdfa436"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0000000e+00],\n",
              "       [1.4850872e-15],\n",
              "       [9.9999142e-01],\n",
              "       [1.0000000e+00],\n",
              "       [6.4135183e-11],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.9999964e-01],\n",
              "       [8.7996703e-09],\n",
              "       [9.9999464e-01],\n",
              "       [1.3727394e-12],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.4531632e-12],\n",
              "       [7.9203331e-11],\n",
              "       [2.6994746e-06]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Post-Processing the results\n",
        "[1 if prediction>0.5 else 0 for prediction in yhat]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l741ZV1N6zNS",
        "outputId": "35957fb4-7340-4a27-c64d-1cf7e5ad4c08"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M21GVJi7I19",
        "outputId": "e341c41d-9fa9-416f-e325-ecd7cb825407"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Recall-Measures how many actual positives are correctly predicted by model\n",
        "\n",
        "#Creating a Metric Object\n",
        "m=Recall()\n",
        "#Calculating Recall Value\n",
        "m.update_state(y_true,yhat)\n",
        "#Return Recall Result\n",
        "m.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIGc6dch7Vdu",
        "outputId": "69a25b69-95f9-407a-824f-646b45997d68"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Precision-Measures how many of the predicted positive instances are actually positive\n",
        "\n",
        "p=Precision()\n",
        "p.update_state(y_true,yhat)\n",
        "p.result().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4oj49g57zkn",
        "outputId": "01a135c5-e638-46da-b613-977b7c570c22"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Visualise Results"
      ],
      "metadata": {
        "id": "Eyz5pqDS9REC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(test_input[0])\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(test_val[0])"
      ],
      "metadata": {
        "id": "pMjRHAsQ9TFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save Model"
      ],
      "metadata": {
        "id": "w4T3l4W7_Dfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model.save('siamese_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POJVU_zS_Fjk",
        "outputId": "4369959a-c096-41b8-cc2d-7b37436d1729"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Model\n",
        "siamese_model = tf.keras.models.load_model('/content/siamese_model.h5', \n",
        "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAlAYlt-_VNe",
        "outputId": "fdbeed8f-53b4-4290-fdd1-f8a89872e5ff"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Real Time Test"
      ],
      "metadata": {
        "id": "P9fHIxrreuex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify(model,detection_threshold,verification_threshold):\n",
        "  '''\n",
        "  Detection Threhold-Metric above which image is considered positive\n",
        "  Verification Threhold-Proportion of positive predictions/total positive samples\n",
        "  '''\n",
        "  results=[]\n",
        "  for image in os.listdir(os.path.join('application_data','verification_images')):\n",
        "    input_img=preprocess(os.path.join('application_data','input_images','input_image.jpg'))\n",
        "    validation_img=preprocess(os.path.join('application_data','verification_images',image))\n",
        "\n",
        "    result=model.predict(list(np.expand_dims([input_img,verification_threshold],axis=1)))\n",
        "    results.append(result)\n",
        "\n",
        "  detection=np.sum(np.array(results)>detection_threshold)\n",
        "  verification=detection/len(os.listdir(os.path.join('application_data','verification_images')))\n",
        "  verified=verification>verification_threshold\n",
        "  return verified"
      ],
      "metadata": {
        "id": "iNsLMMrKewQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(4)\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    frame = frame[120:120+250,200:200+250, :]\n",
        "    \n",
        "    cv2.imshow('Verification', frame)\n",
        "    \n",
        "    # Verification trigger\n",
        "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
        "        cv2.imwrite(os.path.join('application_data', 'input_image', 'input_image.jpg'), frame)\n",
        "        # Run verification\n",
        "        results, verified = verify(siamese_model, 0.9, 0.7)\n",
        "        print(verified)\n",
        "    \n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "lYmGt_Mbmn44"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPf3PNm8wEWgqE9ABd3k89v",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}